{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is currently stored as `.xls` files. In this notebook, we will implement some code to manipulate the data as `pandas.Dataframes` and store as more efficient `.parquet` files on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import any required libraries here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to read the `.xls` files into `pandas.Dataframes`. You can use [pandas.read_excel](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html) for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the building data \n",
    "# consider the different number of header rows!\n",
    "# loading data of different buildings\n",
    "def data_loader(file_name1, file_name2):\n",
    "    \n",
    "    # reading files\n",
    "    df1 = pd.read_excel('/case_study/case_study_data/' + file_name1, header = [2, 3, 4])\n",
    "    df2 = pd.read_excel('/case_study/case_study_data/' + file_name2, header = [2, 3, 4])\n",
    "\n",
    "    concat_df = pd.concat([df1, df2], axis = 0) # concating data frames\n",
    "    \n",
    "    # defining Unique, friendly coulmn name ('first digit of Kennzahl' + 'from fivth digit of Beschreng' + 'Bezeichnung')\n",
    "    concat_df.columns = [x[1][0] + '_' + x[0][5:] + '_' + x[-1]  for x in concat_df.columns]\n",
    "    \n",
    "    concat_df.columns.values[0] = 'Time' # change first column nameto Time\n",
    "    concat_df = concat_df.drop(0, axis = 0) # droping 1st row\n",
    "    concat_df['Time'] = pd.to_datetime(concat_df['Time']) # convert to datetime format\n",
    "    \n",
    "    # converting all variables except Time to float \n",
    "    concat_df[concat_df.columns[~concat_df.columns.isin(['Time'])]] = concat_df[concat_df.columns[~concat_df.columns.isin(['Time'])]].astype('float')\n",
    "    \n",
    "    concat_df = concat_df.sort_values(['Time']) # sort values by time\n",
    "    \n",
    "    concat_df = concat_df.reset_index(drop = True) # reset the index and drop the previous one\n",
    "    \n",
    "    concat_df = concat_df.drop_duplicates(['Time'], keep = 'first') # dropping duplicate rows\n",
    "    \n",
    "    \n",
    "    return concat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to implement a function that takes a `pandas.Dataframe` and a path string as an input and writes the data to disk as a `parquet` file. You can use the [PyArrow library](https://arrow.apache.org/docs/python/parquet.html) for this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n"
     ]
    }
   ],
   "source": [
    "# calling data loader function\n",
    "oh14_df = data_loader(file_name1 = 'OH14.xls', file_name2 = 'OH14_01_26-07_19.xls')\n",
    "oh12_df = data_loader(file_name1 = 'OH12.xls', file_name2 = 'OH12_01_26-07_19.xls')\n",
    "kita_hokida_df = data_loader(file_name1 = 'Kita Hokido.xls', file_name2 = 'Kita Hokido_05_22_20-07_19_22.xls')\n",
    "chemie_df = data_loader(file_name1 = 'Chemie.xls', file_name2 = 'Chemie_01_26-07_19.xls')\n",
    "gross_df = data_loader(file_name1 = 'Großtagespflege.xls', file_name2 = 'Grosstagespflege_04_05-07_19.xls')\n",
    "hg_2_df  = data_loader(file_name1 = 'HG II.xls', file_name2 = 'HGII_01_26-07_19.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_as_parquet(df, path):\n",
    "    # implement this function and add a short doc string describing its use\n",
    "    table = pa.Table.from_pandas(df) # Construct a table from pandas dataframe\n",
    "    pq.write_table(table, path) # pass this table schema to write_table function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing all the files in parquet format\n",
    "write_as_parquet(oh14_df, path = '/case_study/case_study_data/OH14.parquet')\n",
    "write_as_parquet(oh12_df, path = '/case_study/case_study_data/OH12.parquet')\n",
    "write_as_parquet(kita_hokida_df, path = '/case_study/case_study_data/Kita_hokida.parquet')\n",
    "write_as_parquet(chemie_df, path = '/case_study/case_study_data/Chemie.parquet')\n",
    "write_as_parquet(gross_df, path = '/case_study/case_study_data/Großtagespflege.parquet')\n",
    "write_as_parquet(hg_2_df, path = '/case_study/case_study_data/HGII.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need the opposite functionality: a function that reads data from a `.parquet` file on disk and returns it as a `pandas.Dataframe`. Implement this function such that it can take a list of names of column to load as an _optional_ parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_pandas(path, columns):\n",
    "    # implement this function and add a short doc string describing its use\n",
    "    df = pq.read_pandas(path, columns = columns).to_pandas() # reading .parquet file in pandas dataframe format\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>6_11 01 01_Wärmeenergie Tarif 1</th>\n",
       "      <th>6_11 01 01_Durchfluss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-06 11:45:00</td>\n",
       "      <td>2066251.0</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-06 12:00:00</td>\n",
       "      <td>2066251.0</td>\n",
       "      <td>0.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-06 12:15:00</td>\n",
       "      <td>2066251.0</td>\n",
       "      <td>0.134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-07-06 12:30:00</td>\n",
       "      <td>2066252.0</td>\n",
       "      <td>0.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-06 12:45:00</td>\n",
       "      <td>2066252.0</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36269</th>\n",
       "      <td>2022-07-19 01:30:00</td>\n",
       "      <td>2249905.0</td>\n",
       "      <td>0.236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36270</th>\n",
       "      <td>2022-07-19 01:45:00</td>\n",
       "      <td>2249905.0</td>\n",
       "      <td>0.163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36271</th>\n",
       "      <td>2022-07-19 02:00:00</td>\n",
       "      <td>2249906.0</td>\n",
       "      <td>0.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36272</th>\n",
       "      <td>2022-07-19 02:15:00</td>\n",
       "      <td>2249907.0</td>\n",
       "      <td>0.183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36273</th>\n",
       "      <td>2022-07-19 02:30:00</td>\n",
       "      <td>2249907.0</td>\n",
       "      <td>0.193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36248 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Time  6_11 01 01_Wärmeenergie Tarif 1  \\\n",
       "0     2021-07-06 11:45:00                        2066251.0   \n",
       "1     2021-07-06 12:00:00                        2066251.0   \n",
       "2     2021-07-06 12:15:00                        2066251.0   \n",
       "3     2021-07-06 12:30:00                        2066252.0   \n",
       "4     2021-07-06 12:45:00                        2066252.0   \n",
       "...                   ...                              ...   \n",
       "36269 2022-07-19 01:30:00                        2249905.0   \n",
       "36270 2022-07-19 01:45:00                        2249905.0   \n",
       "36271 2022-07-19 02:00:00                        2249906.0   \n",
       "36272 2022-07-19 02:15:00                        2249907.0   \n",
       "36273 2022-07-19 02:30:00                        2249907.0   \n",
       "\n",
       "       6_11 01 01_Durchfluss  \n",
       "0                      0.155  \n",
       "1                      0.126  \n",
       "2                      0.134  \n",
       "3                      0.130  \n",
       "4                      0.128  \n",
       "...                      ...  \n",
       "36269                  0.236  \n",
       "36270                  0.163  \n",
       "36271                  0.158  \n",
       "36272                  0.183  \n",
       "36273                  0.193  \n",
       "\n",
       "[36248 rows x 3 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_to_pandas(path = '/case_study/case_study_data/oh14.parquet', columns = ['Time', '6_11 01 01_Wärmeenergie Tarif 1', '6_11 01 01_Durchfluss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We can now store data more efficiently on disk and know how to load it again. Store all the data we have as one `.parquet` file per building."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
